---
title: "Summary of software contributions to advancing tools in the Earth System Sciences (Action 4)"
subtitle: "NFDI4Earth Deliverable D2.5.6 "
date: 2024-06-30
author: 
  - name: Felix Cremer
    affiliations:
    - ref: mpibgc
  - Fabian Gans
  - Edzer Pebesma
  - Yomna Eid
affiliations:
- id: mpibgc
  name: Max-Planck Institute for Biogeochemistry
  city: Jena
- id: unim
  name: Universit채t M체nster
  city: M체nster
format:
  pdf:
    pdf-engine: pdflatex
  html: default
toc: true
number-sections: true
documentclass: article
---

# Executive Summary


This document lists all contributions to open source solutions for geospatial data analysis and data management, which have been implemented in the frame of the NFDI4Earth  Measure 2.5 until end of Q2 2025. 
Section 2 lists the most important software contributions for different packages with a small description of the aim of every package. 
Section 3 lists other contributions to the open source community and section 4 lists the contributions to documentation and tutorials.

# Software Contributions 

In the first two years of the NFDI4Earth project, M2.5 put its focus on advancing tools in datacube technologies. 
In the open source world, innovative technological solutions are usually developed by a small group of people building solutions for a set of problems in their research area. When these developed solutions prove to be successful they get picked up by other communities and get generalised and formalized to work in a wider set of applications. As these new technologies are not formalized and fully specified from the start this can cause serious interoperability problems because different implementations have different extensions and interpretations of the technology specification. 

For example the Zarr storage format was initially developed by Neuroscientists to store multidimensional MRI data while allowing for efficient cloud storage and access as well as fast parallel read and write operations. Afterwards the storage format was applied in other fields like geoscience to store spatiotemporal data cubes and backends were developed for analysis tools like xarray and dask to access and process this data, making them accesible and interoperable with other datasets. In this process the first large datasets were published, in particular the Pangeo community spearheaded the distribution of large datasets like CMIP6 in the Zarr format on cloud storages. 

While these developments happened in Python only, most of the data analysis is done in high level programming languages like Python, R and Julia or using interfaces in these languages for models in lower level programming languages like C or Fortran. This means that there is currently an accessibility barrier for scientists relying on workflows written in other programming languages or the depending on tools like GDAL written in low-level languages. 

In order to close this gap and to enable better data handling in different programming languages we worked on different Julia and R software packages to remove these access barriers and make these datasets accessible and interoperable with data from other sources in these different programming languages. 
Finally, we participated in the standardisation of the Zarr data format and Fabian Gans is member of the Zarr Implementation Council. We also participated in the pangeo community to enable the documentation of good data handling practices. 
There is currently an OGC working group to establish a new GeoZarr standard for handling geospatial data in Zarr.
Felix Cremer participates in the working group meetings regularly. 



The software and community contributions are listed per package with a short description of the purpose of the packages.

## YAXArrays.jl
YAXArrays.jl is an open source Julia library for large-scale computations on gridded datasets.
These datasets are used for example in global climate models and remote sensing.
These datasets can be larger than the RAM memory of the computer so that they need to be loaded from disk in smaller chunks.
YAXArrays.jl provides access to a variety of file formats like Zarr, NetCDF, GeoTiff and more. 
YAXArrays.jl enables large distributed computations by appyling user-defined functions to huge datasets in an efficient way by respecting the underlying chunking structure of the input datasets. 
It automatically supports multi-threaded and distributed computations or a mix of both, depending on the cluster architecture. 
It tries to mimic the data model of the xarray Python library, so that dimension names form the basis of merging broadcast operations.
It is a computational framework on top of the DiskArrays.jl package and uses Zarr.jl, NetCDF.jl and GDAL.jl for the access of different data formats.

In the first year of the NFDI4Earth project the internal representation of the data has been changed to use the DimensionalData.jl package. 
This change enhances the interoperability of different data cube solutions in Julia. 
Besides this large change, multiple pull requests with bug fixes and performance improvements as well as contributions to the documentation have been provided.


## Zarr.jl

We contributed to both the Zarr specifications and to improvements of the julia Zarr implementation. The improvements include a change in the interpretation of fill values to be conformant with the Zarr specifications and to match other implementations, performance improvements for reading data from web resources as well as reviewing several pull requests with bug fixes and documentation improvements. 

## PyramidScheme.jl

PyramidScheme.jl is a Julia package for the computation and handling of image pyramids for large gridded datasets. 
The image pyramids can then be used for a fast and interactive visualisation of the data in thematic viewers.
It currently works for the computation of two dimensional aggregations with user-defined aggregation functions.
The pyramids can then also be used for subsequent analysis of the data. 
We implemented on the fly computations on the data so that multiple pyramids can be combined in elementwise computations.
The PyramidScheme.jl package is available as open source software at https://github.com/JuliaDataCubes/PyramidScheme.jl.
PyramidScheme.jl is built on top of DiskArrayEngine.jl.
A next step is to  enable read and write to the emerging metadata standards for the handling of pyramid data information so that the image pyramids can be exchanged between different programming languages. 

## DiskArrays.jl

We continued work on supporting infrastructure in the JuliaGeo ecosystem by rewriting large parts of the DiskArrays.jl
Julia package, improving performance, correctness in many edge cases and test coverage. The library provides an interface for performing array operations on out-of-core data which is stored
on disk. It provides a common supertype for almost all ESS-related gridded data formats in Julia and has more than 40 direct and indirect downstream dependents, including ArchGDAL, NetCDF, NCDatasets, GribDatasets, Zarr and therefore provides a unified interface for working with large remote- or diskbased data.

## DiskArrayEngine.jl

DiskArrayEngine.jl is a package that provides a general-purpose computing backend for DiskArray based data. 
It aims to provide a functionality that is similar to the dask library in python by providing parallalism and automatic scaling of the computation. 
In contrast to dask it will not construct huge task graphs.
DiskArrayEngine.jl is used as a backend for the computations in PyramidScheme.jl


## Zarr Reading and Writing in R with `stars`

The R package `stars` has been augmented with functions `read_mdim()` and `write_mdim()` that read and write multidimensional arrays using GDAL's C++ API for multidimensional arrays. This API currently supports reading and writing NetCDF and Zarr files, and requires GDAL version 3.5. It supports partial reads of large data cubes by limiting the extent and resolution on each dimension.


## Other R packages

The R package `terra` has also undergone strong developments recently, and supports reading and writing of datacubes both using the NetCDF library directly or using the GDAL MultiDimensional Array C++ API. The package represents data in `SpatRaster` objects, which can hold up to three-dimensional datacubes.

# Community Participation

## Zarr-specs

The Zarr format is a community-driven data format as described in [Deliverable D2.5.1](https://zenodo.org/record/7951050). The current version of the Zarr specification (v2) has seen wide adoption in different communities (Neuroscience, Climate and Earth System Sciences) as a cloud-compatible alternative to HDF5. One of the members of M2.5 (Fabian Gans) became member of the [Zarr Implementation Council](https://zarr.dev/zeps/zic/) with contributions to the discussion on further improvmements on the Zarr specification. During the last reporting period we helped shaping the upcoming v3 of the Zarr specs in several discussions on github, in particular by emphasizing interoperability of the standard across different programming languages and contributed to the final review of this [new version of the data format](https://zarr.dev/zeps/draft/ZEP0001.html). 

## GeoZarr OGC Working group

Since there are certain intricacies in using geospatial data the GeoZarr working group aims to submit an OGC standard for geospatial data which is saved in the Zarr format. 
We are working as members of Measure 2.5 in this working group especially on the discussions around the standardisation of the pyramid format.
This standardisation is important so that different thematic viewer can work with many Zarr datasets from different sources.


## Workshop on Spatial Data Science across Languages (SDSL)

To enable the exchange of data sets which have been generated in different programming languages it is important to agree on data standards for the storage of such datasets. 
A workshop on geospatial analysis in Python, Julia and R was held
in September 2023 at the Institute for Geoinformatics in M체nster. 
The workshop proved to be very successful in bringing together developers of geospatial scientific 
software packages from different communities, and a main focus of the workshop was the harmonization of existing
standards across package ecosystems from different programming languages, improving interoperability.

Due to the success of the first workshop, a follow-up workshop was  held in September 2024 [link](https://spatial-data-science.github.io/2024/).
And a third edition will be held in [September 2025 in Salzburg](https://spatial-data-science.github.io/2025/)
The results of these workshops have been published as a [preprint](https://arxiv.org/abs/2503.16686) highlighting the common challenges in working with geospatial data programmatically.


## Pangeo-Europe
We participate in the Pangeo-Europe community to learn further about data handling challenges in different communities of the Earth System Sciences which have to deal with large data. 
In the scope of the Pangeo community we participated in a [C-SCALE](https://c-scale.eu/) use case to test the bring your algorithm to the data approach with the YAXArrays.jl package. The C-SCALE project enables working with Copernicus data in the European Open Science Cloud. 


# Tutorials and Documentation

We disseminated the use of the data cube solutions that we are developing by improving the documentation 
and also by providing online and offline tutorials for working with raster data cubes like 
- [Julia EO Workshop](https://aircentre.github.io/JuliaEO/)
- [Pangeo Show & Tell](https://reliance.rohub.org/77a61d94-3318-4d33-a3c0-4730e7026fdb?activetab=overview)
- [NFDI4Earth Academy Online Course](https://www.nfdi4earth.de/?view=article&id=401&catid=9) with [materials](https://juliadatacubes.github.io/datacubes_in_julia_workshop/)


The recordings of these tutorials are available for future use.
We collect the materials for such tutorials at https://github.com/JuliaGeo/JuliaGeoTutorials.

The vector data cube is a progression of the data cube concept on data with arbitrary underlying geometries see  https://www.r-bloggers.com/2022/09/vector-data-cubes/ for an introduction of the idea.
To enable the use of this concept in different programming languages we provided introduction tutorials at [EGU 2025](https://meetingorganizer.copernicus.org/EGU25/session/55010) and [Living Planet Symposium 2025](https://lps25.esa.int/programme/programme-session/?id=F8A45A91-6492-462A-8FAB-C97EF4E61E4A). 
The material of these tutorials is available at https://github.com/Yomna-Eid/VectorRaster-EODataCubes.