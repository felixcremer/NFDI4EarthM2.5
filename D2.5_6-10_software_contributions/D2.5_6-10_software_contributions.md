# Summary of software contributions to advancing tools in the Earth System Sciences (Action 4)


This document lists all software contributions to open source solutions for the handling and analysis of large gridded datasets, that have been implemented in the frame of the NFDI4Earth  Measure 2.5 until end of Q2 2023. 


## Software Contributions 

In the first year of the NFDI4Earth project, M2.5 put its focus on advancing tools in datacube technologies. 
In the open source world, innovative technological solutions are usually developed by a small group of people building solutions for a set of problems in their research area. When these developed solutions prove to be successful they get picked up by other communities and get generalised and formalized to work in a wider set of applications. As these new technologies are not formalized and fully specified from the start this can cause serious interoperability problems because different implementations have different extensions and interpretations of the technology specification. 

For example the zarr storage format was initially developed by Neuroscientists to store multidimensional MRI data while allowing for efficient cloud storage and access as well as fast parallel read and write operations. Afterwards the storage format was applied in other fields like geoscience to store spatiotemporal data cubes and backends were developed for analysis tools like xarray and dask to access and process this data, making them accesible and interoperable with other datasets. In this process the first large datasets were published, in particular the Pangeo community spearheaded the distribution of large datasets like CMIP6 in the zarr format on cloud storages. 

While these developments happened in python only, most of the data analysis is done in high level programming languages like Python, R and Julia or using interfaces in these languages for models in lower level programming languages like C or Fortran. This means that there was an accessibility barrier for scientists relying on workflows written in other programming lagnuages or the depending on tools like GDAL written in low-level languages. 

In order to close this gap and to enable better data handling in different programming languages we worked on different Julia and R software packages to remove these access barriers and make these datasets accessible and interoperable with data from other sources in these different programming languages. 
We also participated in the standardisation of the Zarr data format and Fabian Gans is member of the Zarr Implementation Council. We also participated in the pangeo community to enable the exchange of good data handling practices.

The software and community contributions are listed per package with a short description of the purpose of the packages.

### YAXArrays.jl (Felix)
YAXArrays.jl is an open source Julia library for large-scale computations on larger than memory gridded datasets. It provides access to a variety of file formats like Zarr, NetCDF, GeoTiff and more. 
YAXArrays.jl enables large distributed computations by appyling arbitrary user-defined functions to huge datasets in an efficient way by respecting the underlying chunking structure of the input datasets. 
Automatically supports multi-threaded and distributed computations or a mix of both, depending on the cluster architecture. 
It tries to mimic the data model of the xarray python library, so that dimension names form the basis of merging broadcast operations.
It is a computational framework on top of the DiskArrays.jl package and uses Zarr.jl, NetCDF.jl and GDAL.jl for the access of different data formats.

In the first year of the NFDI4Earth project the internal representation of the data has been changed to use the DimensionalData.jl package. 
This change enhances the interoperability of different data cube solutions in Julia. 
Besides of this large change multiple pull requests with bug fixes and performance improvements as well as contributions to the documentation have been worked on.

### zarr-specs

The zarr format is a community-driven data format as described in (link to first deliverable). The current version of the zarr specification (v2) has seen wide adoption in different communities (Neuroscience, Climate and Earth System Sciences) as a cloud-compatible alternative to HDF5. One of the members of M2.5 (Fabian Gans) became member of the [Zarr Implementation Council](https://zarr.dev/zeps/zic/) with contributions to the discussion on further improvmements on the zarr specs. During the last reporting period we helped shaping the upcoming v3 of the zarr specs in several discussions on github, in particular by emphasizing interoperability of the standard across different programming languages and contributed to the final review of this [new version of the data format](https://zarr.dev/zeps/draft/ZEP0001.html). 



### Zarr.jl

In addition to contributing to the zarr specifications we also contributed to improvements of the julia Zarr implementation. The improvmements include an change in the interpretation of fill values to be conformant with the zarr specs and to match other implementations, performance improvements for reading data from web resources as well as reviewing several pull requests with bug fixes and documentation improvements. 

### Zarr Reading in R (Edzer)

### Pangeo-Europe
We participate in the Pangeo-Europe community to learn further about data handling challenges in different communities of earth system science which have to deal with large data. 
In the scope of the Pangeo community we participate in a [C-SCALE](https://c-scale.eu/) use case to test the bring your algorithm to the data approach with the YAXArrays.jl package. The C-SCALE project enables working with Copernicus data in the European Open Science Cloud. 

### Workshop on vector data cubes in Python, Julia and R

The vector data cube is an progression of the data cube concept on data with arbitrary underlying geometries.
To enable the exchange of data sets which have been generated in different programming languages it is important to agree on data standards for the storage of such datasets. 
Therefore, we are planning a workshop on the implementation of vector data cubes in Python, Julia and R. 


### PyramidScheme.jl (Felix)

PyramidScheme.jl is a Julia package for the computation of image pyramids for larger than memory datasets. It currently works for the computation of two dimensional aggregations with user-defined aggregation functions. 
The image pyramids can then be used for a fast and interactive visualisation of the data.

The PyramidScheme.jl package has been developed in the scope of the NFDI4Earth project and a first working prototype is available as free software at https://github.com/JuliaDataCubes/PyramidScheme.jl
A next step is to  enable read and write to the emerging metadata standards for the handling of pyramid data information so that the image pyramids can be exchanged between different programming languages. 




### Other R packages ?
@edzer if you want to mention other R packages or packages in general feel free to add them here.

## Tutorials and Documentation ??

Should we highlight tutorials and documentation we also contributed to?
Example is the JuliaEO workshop in January

